Format:
Question: ...  
Type: Multiple Choice (Single Correct Answer),  Multiple Choice (Multiple Correct Answers), Free Response (Text Answers, Code Expression)
Answer: ...  
Choices: ...  

# Lesson 1:

# Lesson 2:
- Question: Which of following techniques describes this process best: Selecting features by measuring variance describes"?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: Variance Thresholding
	- Choices: Variance Thresholding; Variance Selection; Standard Deviations; Normal Distributions

- Question: Which class or function in sci-kit learn contains an implementation for VarianceThreshold?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: sklearn.feature_selection.VarianceThreshold
	- Choices: sklearn.feature_selection.VarianceThreshold; sklearn.feature_selection.Variancethreshold; sklearn.featureSelection.VarianceThreshold; sklearn.feature_selection.Variance_Threshold; sklearn.feature_selection.variance_threshold

- Question: Which class in sci-kit learn can be used to select features?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: sklearn.feature_selection
	- Choices: sklearn.feature_selection; sklearn.FeatureSelection; sklearn.Feature_Selection
	; sklearn.features

- Question: Which of the following are univariate techniques available in sci-kit learn?
	- Type: Multiple Choice (Multiple Correct Answers)
	- Answer: sklearn.feature_selection.SelectKBest; sklearn.feature_selection.SelectPercentile; sklearn.feature_selection.GenericUnivariateSelect
	- Choices: sklearn.feature_selection.SelectKBest; sklearn.feature_selection.SelectPercentile; sklearn.feature_selection.GenericUnivariateSelect; sklearn.feature_selection.SelectFromModel; sklearn.feature_selection.RFECV

  - Question: Which of following techniques describes this process best: Recursively removing attributes and building a model from the remaining attributes.
  	- Type: Multiple Choice (Single Correct Answer)
  	- Answer: Recursive Feature Extraction
  	- Choices: Recursive Feature Extraction; L1-based feature selection; L2 based feature selection; Tree based feature selection

  - Question: Is it possible to use a machine learning model to select features?
  	- Type: Multiple Choice (Single Correct Answer)
  	- Answer: Yes
  	- Choices: Yes; No

  - Question: Are there any benefits from selecting features?
  	- Type: Multiple Choice (Single Correct Answer)
  	- Answer:Yes
  	- Choices:Yes; No

# Lesson3:

- Question: Which of the following best describes dimension reduction?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: Reducing the number of features
	- Choices: Reducing the number of features; Reducing the number of data points; Reducing the number of hyperparameters; Reducing the number of trees

- Question: Why is dimension reduction helpful?
	- Type: Multiple Choice (Multiple Correct Answers)
	- Answer: There is less data to process so algorithms run faster; Unimportant information is discarded so results are more robust
	- Choices: There are less features so algorithms run faster; Unimportant information is discarded so results are more robust; There are less hyperparameters so making models is easier; There are less data points so algorithms fun faster

- Question: What is perhaps the most common dimension reduction technique?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: PCA
	- Choices: PCA, Random Forest, SVC; CV

- Question: What does PCA stand for?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: Principal Component Analysis
	- Choices: Principal Component Analysis; Principal Compartment Analysis; Primary Component Analysis; Principal Component Addition

- Question: What criteria can be used to determine how many features to keep after applying PCA?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: Fraction of explained variance
	- Choices:  Fraction of explained variance;  Fraction of explained correlation;  Fraction of explained components;  Fraction of explained data

- Question: What assumptions are made by PCA?
	- Type: Multiple Choice (Multiple Correct Answers)
	- Answer: The data are linear, Features that have large variances encode interesting and important signals, The principal components are orthogonal
	- Choices:  The data are linear, Features that have large variances encode interesting and important signals, The principal components are orthogonal; A large matrix must be inverted


# Lesson 4:

- Question: What module in scikit-learn can be used for manifold learning?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: manifold
	- Choices: manifold; manifold_learn; manifold-learn; manifold_learning

- Question: Which of the following models a data set using many local linear approximations?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: Locally Linear Embedding
	- Choices: Locally Linear Embedding; Multidimensional Scaling; Isometric Mapping; t-SNE

- Question: Which of the following uses linear approximations to preserve similarities between data points when transforming the data to a lower dimensional space?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: Multidimensional Scaling
	- Choices: Locally Linear Embedding; Multidimensional Scaling; Isometric Mapping; t-SNE

- Question: When the similarity used in Multidimensional Scaling is a distance and when the space is Euclidean, what technique is Multidimensional Scaling equivalent to?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: PCA
	- Choices: Locally Linear Embedding; PCA; Isometric Mapping; t-SNE

- Question: Which is better at projecting nonlinear relationships in data?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: Manifold Learning
	- Choices: Manifold Learning; PCA

- Question: Which class or function can be be used to perform PCA in sci-kit learn?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: sklearn.decomposition.PCA
	- Choices: sklearn.decomposition.PCA; sklearn.decomposition.pca; sklearn.manifold_learning.PCA; sklearn.principal_component_analysis.PCA

- Question: Which algorithm computes a transformation that produces a manifold generates a graph connecting neighbors?
	- Type: Multiple Choice (Single Correct Answer)
	- Answer: Isometric Mapping
	- Choices: Isometric Mapping;  t-SNE;  Feature Unions; Multidimensional Scaling
