{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Module 2 Assignment\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `# YOUR CODE HERE`. Do not write your answer anywhere else other than where it says `# YOUR CODE HERE`. Anything you write elsewhere will be removed or overwritten by the autograder.\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to the menubar, select Kernel, and restart the kernel and run all cells (Restart & Run all).\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select File â†’ Save and CheckPoint).\n",
    "5. All work must be your own, if you do use any code from another source (such as a course notebook or a website) you need to properly cite the source.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from nose.tools import assert_equal, assert_almost_equal, assert_true, assert_is_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Loading Breast Cancer Data\n",
    "\n",
    "In this assignment, we will work with a breast cancer data set to make predictive models. Before we build a model, we first load the data into the assignment notebook, and randomly sample several rows.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./breast-cancer-wisconsin.data')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Problem 1: Creating Training and Testing Datasets\n",
    "\n",
    "We pass a DataFrame into the data_split function, which is shown below. Your task in this assignment is to complete this function by using the `train_test_split` function available in the scikit learn library to split the input DataFrame into two new DataFrames (i.e., a testing set and training set). Specifically, you must complete the following tasks:\n",
    "- Split the input DataFrame into two new DataFrames, one each for the training and testing data.\n",
    "- The `test_size` argument in `train_test_split` should be set to the `size` parameter.\n",
    "- The random_state argument in `train_test_split` should be set to the `rs` parameter.\n",
    "- Return the training set and the testing DataFrames, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "27f212221b0171b71baed606bbc7e16f",
     "grade": false,
     "grade_id": "p1_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_split(data, size=0.25, rs=0):\n",
    "    '''\n",
    "    Split input DataFrame into train and test DataFrames\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    data: input DataFrame\n",
    "    size: fraction of data to hold out for testing\n",
    "    rs: random state\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Two DataFrames, one for training, and one for testing, respectively\n",
    "    '''\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    trees = tree.DecisionTreeClassifier(max_features = mf, random_state=rs)\n",
    "    predictions = trees.fit(X_train, y_train).predict(X_test)\n",
    "    \n",
    "    return predictions\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4cb3abd05f3446bdbfbfd163b92cd266",
     "grade": true,
     "grade_id": "p1_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Function\n",
    "train, test = data_split(df)\n",
    "\n",
    "# Test return types\n",
    "assert_equal(type(train), pd.DataFrame, msg=\"train is not a DataFrame\")\n",
    "assert_equal(type(test), pd.DataFrame, msg=\"test is not a DataFrame\")\n",
    "\n",
    "# Test return counts\n",
    "assert_equal(train.count()['id'], 512)\n",
    "assert_equal(test.count()['id'], 171)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "We now convert the training and testing data to NumPy arrays to use with the scikit learn library. This also requires defining the dependent feature, in this case `class`, which must be removed from the set of independent features.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "y = train['class']\n",
    "X = train.drop('class', axis = 1)\n",
    "yTest = test['class']\n",
    "XTest = test.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Problem 2: Creating a Logistic Regression Classifier\n",
    "\n",
    "In the following Code cell, you are given a template for the `classify` function. Your task is to complete this function to perform the following tasks:\n",
    "- Create a Logistic Regression classifier by using the LogisticRegression estimator.\n",
    "- Specify the _random\\_state_ to use by using the input `rs` parameter.\n",
    "- Fit the new estimator on `X` (i.e., the features) and `y` (i.e., the labels).\n",
    "- Return the fitted Logistic Regression model\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "9aa8564173320123eeb0d465938ab2ae",
     "grade": false,
     "grade_id": "p2_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def classify(X, y, rs=0):\n",
    "    '''\n",
    "    Create and fit an LR classifier to input data\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    X: NumPy array used for training\n",
    "    y: NumPy array used for training\n",
    "    rs: seed used for random number generator\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The LR model\n",
    "    '''\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    lbls = y_test.values.reshape(y_test.shape[0])\n",
    "    \n",
    "    return confusion_matrix(lbls, y_pred).ravel()\n",
    "    ### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2251fc336c9cbdba40dbb5ebc1a854ec",
     "grade": true,
     "grade_id": "p2_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute linear model by using our new classify function\n",
    "model_lr = classify(X, y, rs=0)\n",
    "\n",
    "# Test Linear Model\n",
    "assert_equal(model_lr.get_params(), \n",
    "             {'C': 1.0,\n",
    "              'class_weight': None,\n",
    "              'dual': False,\n",
    "              'fit_intercept': True,\n",
    "              'intercept_scaling': 1,\n",
    "              'max_iter': 100,\n",
    "              'multi_class': 'ovr',\n",
    "              'n_jobs': 1,\n",
    "              'penalty': 'l2',\n",
    "              'random_state': 0,\n",
    "              'solver': 'liblinear',\n",
    "              'tol': 0.0001,\n",
    "              'verbose': 0,\n",
    "              'warm_start': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Problem 3: Computing Mean Accuracy\n",
    "\n",
    "The Code cell below provides a template for a function that computes the mean accuracy of a given model on test data, which are specified as `X`, the features, and `y`, the labels. Your task is to complete this function by explicitly:\n",
    "- Calculating the mean accuracy for the given model by using these features and labels.\n",
    "- Return the computed mean accuracy.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "dda7bb5c84e44890e4555a7ee950dc82",
     "grade": false,
     "grade_id": "p3_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def mean_acc(model, X, y):\n",
    "    '''\n",
    "    Compute the mean accuracy for a given model and data set.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    model: the model of interest\n",
    "    X: NumPy array containing indepenent data (features)\n",
    "    y: NumPy array containing depenent data (labels)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A float containing the mean accuracy\n",
    "    '''\n",
    "\n",
    "    ### BEGIN SOLUTION\n",
    "    \n",
    "    # Grab positive class probability\n",
    "    y_score_lr = model_lr.decision_function(XTest)\n",
    "\n",
    "    # Compute ROC curve and ROC area\n",
    "    fpr_lr, tpr_lr, thresholds = roc_curve(yTest, y_score_lr, pos_label=4)\n",
    "    roc_auc_lr = auc(fpr_lr, tpr_lr)\n",
    "\n",
    "    # Make the plots\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "    # Plot data and model\n",
    "    ax.plot(fpr_lr, tpr_lr, alpha = 0.5, linestyle='-.',\n",
    "            label=f'LR (AUC = {roc_auc_lr:4.2f})')\n",
    "    \n",
    "    ax.plot([0, 1], [0, 1], alpha = 0.5, \n",
    "            lw=1, linestyle='-', label='Random')\n",
    "    \n",
    "    ax.plot([0, 0, 1], [0, 1, 1], alpha = 0.5, \n",
    "            lw=1, linestyle='-.', label='Perfect')\n",
    "\n",
    "    # Decorate plot appropriately    \n",
    "    ax.set(title='Receiver Operating Characteristic Curve', \n",
    "           xlabel='False Positive Rate', \n",
    "           ylabel='True Positive Rate', \n",
    "           xlim=(-0.05, 1.05),\n",
    "           ylim=(-0.05, 1.05))\n",
    "    \n",
    "    ax.set_aspect('equal')\n",
    "    ax.legend(loc=4, fontsize=16)\n",
    "    sns.despine(offset=5, trim=True)\n",
    "\n",
    "    return roc_auc_lr, ax\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "304ae86583d729ee4027c8bae33f134b",
     "grade": true,
     "grade_id": "p3_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute Accuracy scores for linear model\n",
    "model_lr_scores = mean_acc(model_lr, XTest, yTest)\n",
    "\n",
    "# Test accuracy score\n",
    "assert_almost_equal(0.6257, model_lr_scores, places=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**&copy; 2017: Robert J. Brunner at the University of Illinois.**\n",
    "\n",
    "This notebook is released under the [Creative Commons license CC BY-NC-SA 4.0][ll]. Any reproduction, adaptation, distribution, dissemination or making available of this notebook for commercial use is not allowed unless authorized in writing by the copyright holder.\n",
    "\n",
    "[ll]: https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "data-analytics-accountancy-2",
   "graded_item_id": "Mh7Ie",
   "launcher_item_id": "m2_assignment"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
