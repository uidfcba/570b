{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Module 3 Assignment\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `# YOUR CODE HERE`. Do not write your answer anywhere else other than where it says `# YOUR CODE HERE`. Anything you write elsewhere will be removed or overwritten by the autograder.\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to the menubar, select Kernel, and restart the kernel and run all cells (Restart & Run all).\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select File â†’ Save and CheckPoint).\n",
    "5. All work must be your own, if you do use any code from another source (such as a course notebook or a website) you need to properly cite the source.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from nose.tools import assert_equal, assert_almost_equal, assert_true, assert_is_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Loading Breast Cancer Data\n",
    "\n",
    "In this assignment, we will work with a breast cancer data set to make predictive models. Before we build a model, we first load the data into the assignment notebook, and randomly sample several rows. The second Code cell splits the DataFrame into a training and testing data set, respectively, before creating the features and labels to use for our classification task.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('./breast-cancer-wisconsin.data')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing DataFrames\n",
    "train, test = train_test_split(df, test_size=0.25, random_state=0)\n",
    "\n",
    "# Create training features and label\n",
    "y = train['class']\n",
    "X = train.drop('class', axis=1)\n",
    "\n",
    "# Create testing features and label\n",
    "yTest = test['class']\n",
    "XTest = test.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Problem 1: Creating a Random Forest Classifier\n",
    "\n",
    "For this problem, you will complete the `classify` function, provided below, to complete the following tasks:\n",
    "- Create a random forest classifier by using the `RandomForestClassifier` estimator in the scikit learn library.\n",
    "- When creating the RandomForestClassifier estimator assign the `s_estimators` hyperparameter to the `ne` parameter, assign the `random_state` hyperparameter to the `rs` parameter, and leave the other parameters as their default values.\n",
    "- Fit this `RandomForestClassifier` estimator to the X (which are the features) and y (which are the labels) DataFrames.\n",
    "- Return the RandomForestClassifier model.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "58f921344d6a3a33c79642c8c56462e9",
     "grade": false,
     "grade_id": "p1_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def classify(X, y, rs=0, ne=10):\n",
    "    '''\n",
    "    Create and fit a RandomForestClassifier estimator to training data.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    X : Pandas DataFrame\n",
    "    y : Pandas DataFrame\n",
    "    rs: seed for random number generator\n",
    "    ne: float for number of estimators\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    The RandomForestClassifier estimator\n",
    "    '''\n",
    "    \n",
    "    ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "acb93219e5a8e80ba5e6231c3e7013f9",
     "grade": true,
     "grade_id": "p1_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Classify data by using different numbers of tress in the forest\n",
    "rfc1 = classify(X, y, rs=0, ne=1)\n",
    "rfc5 = classify(X, y, rs=0, ne=5)\n",
    "rfc10 = classify(X, y, rs=0, ne=10)\n",
    "rfc20 = classify(X, y, rs=0, ne=20)\n",
    "\n",
    "# Check solutions\n",
    "assert_almost_equal(rfc1.score(XTest,yTest), 0.9356, places=2)\n",
    "assert_almost_equal(rfc5.score(XTest,yTest), 0.9532, places=2)\n",
    "assert_almost_equal(rfc10.score(XTest,yTest), 0.9415, places=2)\n",
    "assert_almost_equal(rfc20.score(XTest,yTest), 0.9473, places=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "We now load a raw version of the breast cancer data set, which we will use in the remaining two problems. The first Code cell below loads these data and samples several instances. The second Code cell generates features and  labels.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Load uncleaned data\n",
    "df = pd.read_csv('./breast-cancer-wisconsin-not-cleaned.data')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Create labels (y) and features (X)\n",
    "y = df['class']\n",
    "X = df.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Problem 2: Creating a Data Pre-Processing Pipeline\n",
    "\n",
    "Previously, we have often cleaned data, such as the breast cancer dataset, by removing rows that contained a _NaN_. In this problem, however, we will instead create a pipeline that replaces, or imputes, missing values (i.e., _NaN_) with the mean value of the appropriate column. After this, the pipeline will apply a standard scaling to the columns. Thus, to complete this problem, you must explicitly:\n",
    "- Create an `Imputer` by using the scikit learn library. When creating this object, set the `missing_values` argument to `'NaN'`, the `strategy` argument to `'mean'`, the `axis` argument to `0`, and set `copy=False`.\n",
    "- Create a `StandardScaler` by using the scikit learn library, leaving the parameters as their default values.\n",
    "- Create a pipeline. **Important:** The first item in the pipeline must be the `Imputer` with the name `'imp'`, while the second item in the pipeline must be the `StandardScaler` use the name `'ss'`.\n",
    "- Apply the pipeline to fit and transform the features (X) and the labels (y).\n",
    "- Return the preprocessing pipeline and the transformed  features.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e576712f10e2ae3c245a4a48c2bd9e05",
     "grade": false,
     "grade_id": "p2_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "\n",
    "def preprocess(X, y):\n",
    "    '''\n",
    "    Create and fit a RandomForestClassifier pipeline to training data, \n",
    "    and compute the mean accuracy score from the testing data.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    X : Pandas DataFrame\n",
    "    y : Pandas DataFrame\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The pipeline used to clean the data and the cleaned features as a NumPy array\n",
    "    '''\n",
    "\n",
    "    ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "56b0e3b88e4b7c1f91a5802b4c20c546",
     "grade": true,
     "grade_id": "p2_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Apply pipeline to uncleaned data\n",
    "data_pipeline, new_X = preprocess(X, y)\n",
    "\n",
    "# Test pipeline\n",
    "assert_equal(type(data_pipeline), Pipeline, \n",
    "             msg='Please return a pipeline object as the first object')\n",
    "\n",
    "assert_equal(new_X[30][0], -0.0012472123989550703)\n",
    "assert_equal(new_X[100][0], 0.15397593605209656)\n",
    "assert_equal(new_X[123][0], 0.16658267824600242)\n",
    "assert_equal(new_X[256][0], 0.17951699465179008)\n",
    "assert_equal(new_X[512][0], 0.37020734898435897)\n",
    "\n",
    "assert_equal(type(data_pipeline.get_params()['imp']), type(Imputer()), \n",
    "             msg='You  did not label the imputer \"imp\" or did not make an Imputer Object')\n",
    "\n",
    "assert_equal(type(data_pipeline.get_params()['steps'][0][1]), Imputer, \n",
    "             msg='You need to create a Imputer First')\n",
    "\n",
    "assert_equal(data_pipeline.get_params()['imp__missing_values'], 'NaN', \n",
    "             msg='set missing values to NaN')\n",
    "\n",
    "assert_equal(data_pipeline.get_params()['imp__strategy'], 'mean', \n",
    "             msg='Set strategy to mean')\n",
    "\n",
    "assert_equal(type(data_pipeline.get_params()['ss']), type(StandardScaler()), \n",
    "             msg='You  did not create a Standard Scaler labeled \"ss\" ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "We now need to split the newly cleaned data into training and testing data sets in order to create and apply a classifier pipeline to these data.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(new_X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Problem 3: Creating a Random Forest Pipeline\n",
    "\n",
    "For this problem, you will finish the `rfcp` template function provided below by creating a random forest pipeline. This will require that you complete the following tasks:\n",
    "- Create a random forest classifier by using the scikit learn RandomForestClassifer estimator. Do not change any of the default hyperparameters for this estimator.\n",
    "- Create a pipeline that includes this random forest classifier, and label the classifier `rfc`.\n",
    "- Set the random_state of the random forest classifier in the pipeline to the value specified by the `rs` parameter.\n",
    "- Fit the pipeline to the training data.\n",
    "- Calculate the mean accuracy of the random forest classifier in the pipeline from the test data.\n",
    "- Return the pipeline and the mean accuracy score.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6dc713922a26d1d067f6c6eab7e33145",
     "grade": false,
     "grade_id": "p3_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def rfcp(trainX, trainY, testX, testY, rs=0):\n",
    "    '''\n",
    "    Create and fit a RandomForestClassifier pipeline to training data, \n",
    "    and compute the mean accuracy score from the testing data.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    trainX : NumPy array (features)\n",
    "    trainY : NumPy array (labels)\n",
    "    testX : NumPy array (features)\n",
    "    testY : NumPy array (labels)\n",
    "    rs: random state\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The pipeline and a float containing the mean accuracy score\n",
    "    '''\n",
    "\n",
    "    ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7d799bc31332bab5b9c5648f63597fba",
     "grade": true,
     "grade_id": "p3_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Create and apply the RFC pipeline\n",
    "ml_pipeline, score = rfcp(trainX, trainY, testX, testY, rs=0)\n",
    "\n",
    "# Test the pipeline\n",
    "assert_equal(type(ml_pipeline.get_params()['rfc']), type(RandomForestClassifier()))\n",
    "assert_almost_equal(score, 0.9555, places=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**&copy; 2017: Robert J. Brunner at the University of Illinois.**\n",
    "\n",
    "This notebook is released under the [Creative Commons license CC BY-NC-SA 4.0][ll]. Any reproduction, adaptation, distribution, dissemination or making available of this notebook for commercial use is not allowed unless authorized in writing by the copyright holder.\n",
    "\n",
    "[ll]: https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "data-analytics-accountancy-2",
   "graded_item_id": "JlF8G",
   "launcher_item_id": "m3_assignment"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
