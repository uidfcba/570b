{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 1 Assignment\n",
    "\n",
    "A few things you should keep in mind when working on assignments:\n",
    "\n",
    "1. Make sure you fill in any place that says `# YOUR CODE HERE`. Do not write your answer anywhere else other than where it says `# YOUR CODE HERE`. Anything you write elsewhere will be removed or overwritten by the autograder.\n",
    "2. Before you submit your assignment, make sure everything runs as expected. Go to the menubar, select Kernel, and restart the kernel and run all cells (Restart & Run all).\n",
    "3. Do not change the title (i.e. file name) of this notebook.\n",
    "4. Make sure that you save your work (in the menubar, select File â†’ Save and CheckPoint).\n",
    "5. All work must be your own, if you do use any code from another source (such as a course notebook or a website) you need to properly cite the source.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6ff1fb74c64b6c31bf87469169ddf342",
     "grade": false,
     "grade_id": "cell-d95b3d9bf9f7276d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nose.tools import assert_equal, assert_almost_equal, assert_true, assert_is_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Predicting the Price of a Car\n",
    "\n",
    "In this assignment, we will use a partially cleaned dataset to make a predictive model. Before we attempt to build a mode, we first must load the data, select the independent feature, and the dependent label. The first Code cell below reads the data from a CSV file and displays several random instances. The second Code cell selects the independent features (`make`) and the dependent label (`price`), and displays the first few instances in this new DataFrame. \n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./imports-85.data')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df_simple = df[['make', 'price']]\n",
    "df_simple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Problem 1: Creating the Training and Testing Datasets\n",
    "\n",
    "The `data_split` function shown below accepts a parameter called `data` that is stored in a DataFrame. Your task is to use the `train_test_split` function available in the scikit learn library to split this DataFrame into two separate DataFrames (a testing set and training set). \n",
    "\n",
    "To complete this process, do the following:\n",
    "- Split the training and testing set into two separate DataFrames.\n",
    "- The `test_size` argument in `train_test_split` should be set to the `size` parameter.\n",
    "- The `random_state` argument in `train_test_split` should be set the `random_state` parameter.\n",
    "- Return both the training set and the testing set, in this order.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "1349479b8a645e353f227bf24b8d557f",
     "grade": false,
     "grade_id": "p1_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def data_split(data, size=0.25, random_state=0):\n",
    "    '''    \n",
    "    Split data into training and testing sets.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    data: Panadas DataFrame\n",
    "    size: ratio of training and testing data\n",
    "    random_state: random seed for random number generator\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Two DataFrames: train and test, in that order.\n",
    "    '''\n",
    "    \n",
    "    ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ab0e4fa21a55531ab281948dd5b0f54b",
     "grade": true,
     "grade_id": "p1_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Call function\n",
    "train, test = data_split(df_simple)\n",
    "\n",
    "# Test Data types\n",
    "assert_equal(type(train), pd.DataFrame, msg=\"train is not a DataFrame\")\n",
    "assert_equal(type(test), pd.DataFrame, msg=\"test is not a DataFrame\")\n",
    "\n",
    "# Converting to NumPy arrays for sklearn\n",
    "train_X = train.make.values.reshape(len(train.make),1)\n",
    "train_y = train.price.values\n",
    "test_X = test.make.values.reshape(len(test.make), 1)\n",
    "test_y = test.price.values\n",
    "\n",
    "# Test dependent values\n",
    "assert_almost_equal(np.sum(test_y), 689311.38805, places=2)\n",
    "assert_almost_equal(np.sum(train_y), 2018150.12935, places=2)\n",
    "\n",
    "# Test independent values\n",
    "assert_equal(train_X[1][0], 8)\n",
    "assert_equal(train_X[45][0], 13)\n",
    "assert_equal(test_X[25][0], 18)\n",
    "assert_equal(test_X[51][0], 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Problem 2: Performing Linear Regression\n",
    "\n",
    "Your task for this problem is to build and use the scikit learn library's `LinearRegression` estimator to  make predictions on the cars dataset. The framework for a regression function has been provided below, that takes two NumPy arrays containing the features (`trainX`) and the labels (`trainY`), an optional Boolean flag, `fit_intercept`, which indicates whether an intercept term should be fit as part of the linear regression. To complete this function, you must explicitly:\n",
    "- Create a `LinearRegression` estimator by using scikit learn.\n",
    "- Fit the `LinearRegression` estimator using trainX and trainY.\n",
    "- Return the resulting estimator.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8442d1fb728fe4db1772a7b37d0d032c",
     "grade": false,
     "grade_id": "p2_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def regression(trainX, trainY, fit_intercept=False):\n",
    "    '''\n",
    "    Compute a linear regression model for given training data set.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    trainX: the training indepedent features\n",
    "    trainY: the training depedent features\n",
    "    fit_intercept: optional Boolean flag to indicate if an intercept should be fit\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The fitted linear regression model\n",
    "    '''\n",
    "    \n",
    "    ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9da927f178b09d33ab45a577e91d4a3d",
     "grade": true,
     "grade_id": "p2_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "lr = regression(train_X, train_y, fit_intercept=True)\n",
    "\n",
    "assert_equal(type(lr), type(LinearRegression()))\n",
    "assert_equal(lr.get_params(), {'copy_X': True, 'fit_intercept': True, \\\n",
    "                               'n_jobs': 1, 'normalize': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Problem 3: Checking R2 Score on Testing Dataset\n",
    "\n",
    "For this problem, you will compute the R2 score given a model, the independent features (`X`), and the dependent feature (`y`). By using the function template provided below, you must explicitly:\n",
    "- Compute the R2 score for the supplied model.\n",
    "- Return the resulting score.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c7f73d8ffadb87edca43d0d97265fad6",
     "grade": false,
     "grade_id": "p3_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def r2_score(model, X, y):\n",
    "    '''\n",
    "    Compute the R2 score for a given model and data set.\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    model: linear regression model\n",
    "    X: NumPy array containing indepenent data (features)\n",
    "    y: NumPy array containing depenent data (labels)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    A float containing the model score\n",
    "    '''\n",
    "\n",
    "    ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "267ece2cdbe57ae87a9e726cb41374cd",
     "grade": true,
     "grade_id": "p3_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the score\n",
    "score = r2_score(lr, train_X, train_y)\n",
    "\n",
    "# Test the score\n",
    "assert_almost_equal(0.010956, score, places=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "-----\n",
    "\n",
    "## Problem 4: Model Persistence\n",
    "\n",
    "Complete the function `persist_model`, which accepts two parameters: `name` and `model`. This function will persist the provided `model` into a new file specified by `name`. To persist the machine learning model, you should use the joblib library. By using the function template provided below, you must explicitly:\n",
    "- Open the file by using the provided name for writing.\n",
    "- Save the model to this file.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "76509c9a04a0a8b5e99b8e382fe699bf",
     "grade": false,
     "grade_id": "p4_answer",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "def persist_model(name, model):\n",
    "    '''\n",
    "    Write a model to the specified file.\n",
    "\n",
    "    Parameters\n",
    "    ---------   \n",
    "    name: A string containg the filename to which the model should be written.\n",
    "    model: The model that should be saved to the file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Nothing\n",
    "    '''\n",
    "   \n",
    "    ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7451dd64a4d037d8079674ea35fe8be2",
     "grade": true,
     "grade_id": "p4_test",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Save model to temporary file\n",
    "persist_model('test_model.pkl', lr)\n",
    "\n",
    "# Does the file exist?\n",
    "assert_true(os.path.exists('test_model.pkl'))\n",
    "\n",
    "# Test model recreation\n",
    "with open('test_model.pkl', 'rb') as fin:\n",
    "    new_model = joblib.load(fin)\n",
    "    assert_equal(new_model.fit_intercept, True)\n",
    "\n",
    "# Remove the temporary file\n",
    "!rm test_model.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**&copy; 2017: Robert J. Brunner at the University of Illinois.**\n",
    "\n",
    "This notebook is released under the [Creative Commons license CC BY-NC-SA 4.0][ll]. Any reproduction, adaptation, distribution, dissemination or making available of this notebook for commercial use is not allowed unless authorized in writing by the copyright holder.\n",
    "\n",
    "[ll]: https://creativecommons.org/licenses/by-nc-sa/4.0/legalcode "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "data-analytics-accountancy-2",
   "graded_item_id": "GrQNK",
   "launcher_item_id": "m1_assignment"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
